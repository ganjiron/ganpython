{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "io5uKjor1uCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIRzNc3g1yym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define constants\n",
        "#unrolled through 100 time steps\n",
        "time_steps=100\n",
        "#hidden LSTM units\n",
        "num_units=200\n",
        "#rows of 12 sensors\n",
        "n_input=12\n",
        "#learning rate for adam\n",
        "learning_rate=0.001\n",
        "#this is meant to be classified in 6 classes{'jog': 0, 'dws': 1, 'ups': 2, 'wlk': 3, 'sit': 4, 'std': 5}\n",
        "n_classes=6\n",
        "#size of batch\n",
        "batch_size=120"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5gjrVpb32E19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33afa07a-5d67-4520-ba30-7a79c3759798"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KEmyFlYc2FnF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"/content/gdrive/My Drive/train_data.csv\")\n",
        "test_data = pd.read_csv(\"/content/gdrive/My Drive/test_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3mhCx0W2UUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataTemp : CSV input/out 섞여있는 데이터 \n",
        "# period : 자를 timeSteps\n",
        "# onehot : default True, 원핫으로 return 할지 말지 결정\n",
        "# return : 다 만들어진 X , Y\n",
        "def dataPreprocessing(dataTemp , period , onehot = True , dropCol = True ):\n",
        "    encoding = {'jog': 0, 'dws': 1, 'ups': 2, 'wlk': 3, 'sit': 4, 'std': 5}\n",
        "    retY = pd.Series([])\n",
        "#     retY = np.array([])\n",
        "    retX = dataTemp\n",
        "    temptype = -1\n",
        "    cnt = 0\n",
        "    dataTemp[\"type_1\"] = dataTemp[\"user_id\"].map(str) +\"_\"+ dataTemp[\"action_id\"]\n",
        "    \n",
        "    for dataIter in range(dataTemp[\"action_id\"].size//period):\n",
        "        retY[cnt] = encoding[dataTemp[\"action_id\"].iloc[dataIter*period][:3]]\n",
        "        comp = dataTemp[\"type_1\"].iloc[dataIter*period]\n",
        "        if comp == temptype:\n",
        "            cnt += 1\n",
        "        else:\n",
        "#             print(cnt)\n",
        "            temptype = comp\n",
        "#             cnt += 1\n",
        "            retX = retX.drop(retX.index[dataIter:dataIter+period])\n",
        "    if onehot:\n",
        "        retY = pd.get_dummies(retY)\n",
        "    if dropCol:\n",
        "        retX = retX.drop([\"action_id\"] , axis = 1)\n",
        "        retX = retX.drop([\"user_id\"] , axis = 1)\n",
        "        retX = retX.drop([\"time_50hz\"] , axis = 1)\n",
        "        retX = retX.drop([\"type_1\"] , axis = 1)\n",
        "    return retX , retY\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1pWMGsGujUT0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataTemp : CSV input/out 섞여있는 데이터 \n",
        "# period : 자를 timeSteps\n",
        "# onehot : default True, 원핫으로 return 할지 말지 결정\n",
        "# return : 다 만들어진 X , Y\n",
        "def dataPreprocessingWithNormal(dataTemp , period , onehot = True , dropCol = True ):\n",
        "  encoding = {'jog': 0, 'dws': 1, 'ups': 2, 'wlk': 3, 'sit': 4, 'std': 5}\n",
        "  retY = pd.Series([])\n",
        "#     retY = np.array([])\n",
        "  retX = dataTemp\n",
        "  retX_X = pd.DataFrame([])\n",
        "  temptype = -1\n",
        "  cnt = 0\n",
        "  dataTemp[\"type_1\"] = dataTemp[\"user_id\"].map(str) +\"_\"+ dataTemp[\"action_id\"]\n",
        "\n",
        "#   for i in set(dataTemp[\"type_1\"]):\n",
        "  a = dataTemp\n",
        "  a = a.drop([\"action_id\"] , axis = 1)\n",
        "  a = a.drop([\"user_id\"] , axis = 1)\n",
        "  a = a.drop([\"time_50hz\"] , axis = 1)\n",
        "  a = a.drop([\"type_1\"] , axis = 1)\n",
        "  normalized_df=(a-a.mean())/a.std()\n",
        "  retX_X = retX_X.append( normalized_df )\n",
        "#     x = a.values\n",
        "#     min_max_scaler = preprocessing.MinMaxScaler()\n",
        "#     x_scaled = min_max_scaler.fit_transform(x)\n",
        "#     retX_X = retX_X.append( pd.DataFrame(x_scaled) )\n",
        "  retX_X = retX_X.reset_index(drop=True)\n",
        "#   print(retX_X.shape)\n",
        "\n",
        "\n",
        "  for dataIter in range(dataTemp[\"action_id\"].size//period):\n",
        "    retY[cnt] = encoding[dataTemp[\"action_id\"].iloc[dataIter*period][:3]]\n",
        "    comp = dataTemp[\"type_1\"].iloc[dataIter*period]\n",
        "#     print(dataTemp.shape , retX_X.shape)\n",
        "    if comp == temptype:\n",
        "      cnt += 1\n",
        "    elif temptype == -1 :\n",
        "      cnt += 1\n",
        "    else:            \n",
        "      temptype = comp\n",
        "      retX_X = retX_X.drop(retX_X.index[dataIter:dataIter+period])\n",
        "#             print(dataTemp.shape . retX_X.shape)\n",
        "  if onehot:\n",
        "    retY = pd.get_dummies(retY)\n",
        "#     if dropCol:\n",
        "#         retX = retX.drop([\"action_id\"] , axis = 1)\n",
        "#         retX = retX.drop([\"user_id\"] , axis = 1)\n",
        "#         retX = retX.drop([\"time_50hz\"] , axis = 1)\n",
        "#         retX = retX.drop([\"type_1\"] , axis = 1)\n",
        "#   print(retX_X.shape)\n",
        "  return retX_X , retY\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dm4iDZPc2d7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_X , train_Y = dataPreprocessingWithNormal(train_data , time_steps , True)\n",
        "test_X , test_Y = dataPreprocessingWithNormal(test_data , time_steps , True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ga5RFKx43QID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_X , train_Y = dataPreprocessing(train_data , time_steps , True)\n",
        "test_X , test_Y = dataPreprocessing(test_data , time_steps , True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YXP0KvQMthCJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tempaaa = pd.DataFrame([])\n",
        "for i in set(train_data[\"type_1\"]):\n",
        "  a = train_data[(train_data[\"type_1\"]==i)]\n",
        "  a = a.drop([\"action_id\"] , axis = 1)\n",
        "  a = a.drop([\"user_id\"] , axis = 1)\n",
        "  a = a.drop([\"time_50hz\"] , axis = 1)\n",
        "  a = a.drop([\"type_1\"] , axis = 1)\n",
        "  normalized_df=(a-a.mean())/a.std()\n",
        "  tempaaa = tempaaa.append( normalized_df )\n",
        "tempaaa = tempaaa.reset_index(drop=True)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gaXrQA7r7KBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11917135-65ea-4b6a-9934-0564e9814f31"
      },
      "cell_type": "code",
      "source": [
        "train_X.shape , train_Y.shape , test_X.shape , test_Y.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1209003, 12), (12090, 6), (167862, 12), (1678, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "Qj-_ZQZg2fhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98ac858a-5199-48ac-818e-0f804bdb67aa"
      },
      "cell_type": "code",
      "source": [
        "train_X.shape , train_Y.shape , test_X.shape , test_Y.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1209003, 12), (12090, 6), (167862, 12), (1678, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "j5BIEL-_2hUl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#weights and biases of appropriate shape to accomplish above task\n",
        "out_weights=tf.Variable(tf.random_normal([num_units,n_classes]))\n",
        "out_bias=tf.Variable(tf.random_normal([n_classes]))\n",
        "\n",
        "#defining placeholders\n",
        "#input image placeholder\n",
        "x=tf.placeholder(tf.float32 ,[None,time_steps , n_input])\n",
        "#input label placeholder\n",
        "y=tf.placeholder(tf.int32 ,[None,n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1otAwvbq2i90",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input=tf.unstack(x ,time_steps,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YSMby1th2kZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8bfbc5cd-3b0d-4109-f246-ae72c6d12bfb"
      },
      "cell_type": "code",
      "source": [
        "#defining the network\n",
        "lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=0.9)\n",
        "outputs,_=rnn.static_rnn(lstm_layer,input,dtype=\"float32\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-42-ff2453f146cf>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CmRrKL5G2lnN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\n",
        "prediction=tf.matmul(outputs[-1],out_weights)+out_bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9f_WjbnN58wQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Yhat = tf.argmax(prediction,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hgULriTM2my2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loss_function\n",
        "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y))\n",
        "#optimization\n",
        "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n",
        "#model evaluation\n",
        "correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7StUIZE22nwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "fa0f16b6-bb7c-4303-fe05-1bdb4c1b6043"
      },
      "cell_type": "code",
      "source": [
        "#initialize variables\n",
        "init=tf.global_variables_initializer()\n",
        "test_X_temp = np.array(test_X[:160000]).reshape(-1,time_steps , n_input)\n",
        "epoch = 50\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(init)\n",
        "for ep  in range(1,epoch+1):    \n",
        "    iter=0\n",
        "    while iter<99:\n",
        "        batch_x = train_X[iter*batch_size*time_steps:(iter+1)*batch_size*time_steps]\n",
        "        batch_y = train_Y[iter*batch_size:(iter+1)*batch_size]\n",
        "        batch_x = np.array(batch_x)\n",
        "        batch_x=batch_x.reshape((batch_size,time_steps,n_input))\n",
        "        sess.run(opt, feed_dict={x: batch_x, y: batch_y})  \n",
        "#             if iter % 10 == 0:\n",
        "#                 acc=sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\n",
        "#                 los=sess.run(loss,feed_dict={x:batch_x,y:batch_y})\n",
        "        iter=iter+1\n",
        "    if ep % 5 == 0:            \n",
        "        test_acc = sess.run(accuracy, feed_dict={x: test_X_temp, y: test_Y[:1600]})\n",
        "        test_los = sess.run(loss, feed_dict={x: test_X_temp, y: test_Y[:1600]})\n",
        "        print(\"Epoch {} , Test Acc {} , los {} \".format(ep,test_acc , test_los))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 , Test Acc 0.4268749952316284 , los 2.708103656768799 \n",
            "Epoch 10 , Test Acc 0.5450000166893005 , los 1.451491117477417 \n",
            "Epoch 15 , Test Acc 0.7131249904632568 , los 1.2066409587860107 \n",
            "Epoch 20 , Test Acc 0.7681249976158142 , los 1.0570793151855469 \n",
            "Epoch 25 , Test Acc 0.7825000286102295 , los 1.0439800024032593 \n",
            "Epoch 30 , Test Acc 0.7931249737739563 , los 1.081236720085144 \n",
            "Epoch 35 , Test Acc 0.7881249785423279 , los 1.1663413047790527 \n",
            "Epoch 40 , Test Acc 0.28125 , los 10.241960525512695 \n",
            "Epoch 45 , Test Acc 0.765625 , los 1.0639581680297852 \n",
            "Epoch 50 , Test Acc 0.7743750214576721 , los 1.1466714143753052 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R3tt5-mGHT1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test_data_eval 에 분류를 위한 type_1 을 넣는데.\n",
        "test_data_eval = test_data\n",
        "test_data_eval[\"type_1\"] = test_data[\"user_id\"].map(str) +\"_\"+ test_data[\"action_id\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T6WzHb-aXHaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "79bd6a63-92da-429f-8aa7-6ee35ef5bbbc"
      },
      "cell_type": "code",
      "source": [
        "# type 의 종류를 가지고 와서 나중에 loop 를 돌면서 accuracy 를 만들것임\n",
        "dic_testType = list(set(test_data_eval[\"type_1\"]))\n",
        "dic_testType"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2_jog_9',\n",
              " '1_sit_5',\n",
              " '2_jog_16',\n",
              " '2_sit_5',\n",
              " '1_wlk_15',\n",
              " '1_wlk_8',\n",
              " '2_std_14',\n",
              " '2_ups_4',\n",
              " '1_jog_9',\n",
              " '1_std_6',\n",
              " '2_wlk_7',\n",
              " '2_ups_3',\n",
              " '3_wlk_8',\n",
              " '1_dws_11',\n",
              " '3_jog_16',\n",
              " '1_ups_3',\n",
              " '3_std_14',\n",
              " '3_dws_11',\n",
              " '3_dws_1',\n",
              " '1_ups_4',\n",
              " '1_dws_1',\n",
              " '1_sit_13',\n",
              " '3_dws_2',\n",
              " '1_wlk_7',\n",
              " '3_ups_3',\n",
              " '2_wlk_8',\n",
              " '3_ups_12',\n",
              " '2_wlk_15',\n",
              " '1_dws_2',\n",
              " '1_std_14',\n",
              " '2_dws_2',\n",
              " '1_ups_12',\n",
              " '3_sit_13',\n",
              " '3_jog_9',\n",
              " '3_std_6',\n",
              " '3_wlk_7',\n",
              " '2_std_6',\n",
              " '2_ups_12',\n",
              " '3_ups_4',\n",
              " '1_jog_16',\n",
              " '3_sit_5',\n",
              " '2_sit_13',\n",
              " '3_wlk_15',\n",
              " '2_dws_11',\n",
              " '2_dws_1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "y5Wc0FCyXHc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c879f4e9-7f43-47f8-f692-dcf57602efaf"
      },
      "cell_type": "code",
      "source": [
        "# full loop 만들어보기\n",
        "y_pred = []\n",
        "y_true = []\n",
        "# >>> accuracy_score(y_true, y_pred)\n",
        "for ite in dic_testType:\n",
        "    # 한 타입만 일단 가져와보고\n",
        "    tempX = test_data_eval[(test_data_eval[\"type_1\"] == ite)]\n",
        "    # matrix 에 맞게 뒤에 잘라내줌.\n",
        "    tempX = tempX[:(tempX.shape[0] // time_steps)*time_steps]\n",
        "    # 여기에서 데이터를 X,Y 로 먼저 나눠준다. onehot 해뒀고 필요없는 column 까지 다 Drop\n",
        "    evalTestX , evalTestY = dataPreprocessing(tempX , time_steps , True , True)\n",
        "    evalTestX = np.array(evalTestX).reshape(-1,time_steps , n_input)\n",
        "    # one hot 에 하나만 있기때문에 나머지 다 넣어주고 순서 원래대로 변경\n",
        "#         for i in range(6):\n",
        "#             if i not in set(evalTestY):\n",
        "#                 evalTestY[i] = 0\n",
        "#         evalTestY=evalTestY[[0,1,2,3,4,5]]\n",
        "    yh = sess.run(Yhat , feed_dict={x:evalTestX})\n",
        "    pre = Counter(yh).most_common(1)[0][0]\n",
        "    tru = evalTestY.columns[0]\n",
        "    y_pred.append(pre)\n",
        "    y_true.append(tru)\n",
        "    if(pre != tru):\n",
        "      print(\"ite : \" , ite , ' predict : ' , yh ,\":\" ,pre, \" Real Y : \" , tru)\n",
        "    \n",
        "#     print(\"ite : \" , ite , ' predict : ' , yh ,\":\" ,pre, \" Real Y : \" , tru)\n",
        "#     print('predict : ' , pre , \" Real Y : \" , tru)\n",
        "#     print(evalTestX.shape , evalTestY.shape , ite)}"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ite :  2_ups_3  predict :  [0 2 0 2 0 2 0 1] : 0  Real Y :  2\n",
            "ite :  1_ups_3  predict :  [3 3 2 3 3 2 3 3 3 2 3 3 2 2 3 3 2 3] : 3  Real Y :  2\n",
            "ite :  1_ups_4  predict :  [3 2 2 3 3 2 3 3 2 3 3 1 2 3 5 2 3 3 3 2 2 3 3 2 3] : 3  Real Y :  2\n",
            "ite :  1_std_14  predict :  [4 3 3 3 3 0 4 3 3 3 3 0 4 3 3 3 3 3 4 3 3 3 3 3 3 4 3 3 3 3 3] : 3  Real Y :  5\n",
            "ite :  1_ups_12  predict :  [1 2 3 3 3 3 3 3] : 3  Real Y :  2\n",
            "ite :  2_ups_12  predict :  [0 2] : 0  Real Y :  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "99X-I-XawJko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcd4ed8a-dadc-4ffc-ed2c-0e3f0a633406"
      },
      "cell_type": "code",
      "source": [
        "accuracy_score(y_true, y_pred)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "wvb3GImsVRHV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}