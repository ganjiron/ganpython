{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "spark = SparkSession.builder.appName(\"Ch02_1\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "data = sc.textFile(\"sample_movielens_ratings.txt\")\n",
    "ratings = data.map(lambda l: l.split('::'))\\\n",
    "    .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.049912029118531584\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(ratings, rank, numIterations)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "testdata = ratings.map(lambda p: (p[0], p[1]))\n",
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, \"target/tmp/myCollaborativeFilter\")\n",
    "sameModel = MatrixFactorizationModel.load(sc, \"target/tmp/myCollaborativeFilter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ALS' has no attribute 'trainImplicit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8fd4fb7ce70a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m#     als = ALS(maxIter=numIterations, regParam=0.11, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mALS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainImplicit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumIterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'ALS' has no attribute 'trainImplicit'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Licensed to the Apache Software Foundation (ASF) under one or more\n",
    "# contributor license agreements.  See the NOTICE file distributed with\n",
    "# this work for additional information regarding copyright ownership.\n",
    "# The ASF licenses this file to You under the Apache License, Version 2.0\n",
    "# (the \"License\"); you may not use this file except in compliance with\n",
    "# the License.  You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "if sys.version >= '3':\n",
    "    long = int\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# $example on$\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# from pyspark.ml.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from pyspark.sql import Row\n",
    "# $example off$\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ALSExample\")\\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    rank = 10\n",
    "    numIterations = 10\n",
    "\n",
    "    # $example on$\n",
    "    lines = spark.read.text(\"sample_movielens_ratings.txt\").rdd\n",
    "    parts = lines.map(lambda row: row.value.split(\"::\"))\n",
    "    ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
    "                                         rating=float(p[2]), timestamp=long(p[3])))\n",
    "    ratings = spark.createDataFrame(ratingsRDD)\n",
    "    (training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "    # Build the recommendation model using ALS on the training data\n",
    "    # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "#     als = ALS(maxIter=numIterations, regParam=0.11, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "    model = ALS.trainImplicit(ratings, rank, numIterations, alpha=0.01)\n",
    "    model = als.fit(training)\n",
    "\n",
    "    # Evaluate the model by computing the RMSE on the test data\n",
    "    predictions = model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "    # Generate top 10 movie recommendations for each user\n",
    "    userRecs = model.recommendForAllUsers(10)\n",
    "    # Generate top 10 user recommendations for each movie\n",
    "    movieRecs = model.recommendForAllItems(10)\n",
    "\n",
    "    # Generate top 10 movie recommendations for a specified set of users\n",
    "    users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "    userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "    # Generate top 10 user recommendations for a specified set of movies\n",
    "    movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "    movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n",
    "    # $example off$\n",
    "    userRecs.show()\n",
    "    movieRecs.show()\n",
    "    userSubsetRecs.show()\n",
    "    movieSubSetRecs.show()\n",
    "\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
