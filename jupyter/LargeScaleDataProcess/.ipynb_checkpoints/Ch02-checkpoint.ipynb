{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Introduction to Data Analysis with Scala and Spark\n",
    "\n",
    "이 주피터 파일과 같은 디렉토리에 linkage_csv디렉토리만 있으면 됩니다\n",
    ">**window**   \n",
    " curl -L -o donation.zip https://bit.ly/1Aoywaq  \n",
    " 7z x donation.zip -o./linkage  \n",
    " 7z x linkage/block_\\*.zip -o./linkage_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Ch02\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-SO3U0T7N:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Ch02</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Ch02>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing Data from the Cluster to the Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c:\\linkage_csv MapPartitionsRDD[1] at textFile at <unknown>:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# block_*.csv만 따로 모아놓은 디렉토리\n",
    "rawblocks = sc.textFile(\"c:\\\\linkage_csv\")\n",
    "rawblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o29.partitions.\n: java.lang.RuntimeException: Error while running command to get file permissions : java.io.IOException: (null) entry in command string: null ls -F C:\\linkage_csv\\block_1.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:770)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:866)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:849)\r\n\tat org.apache.hadoop.fs.FileUtil.execCommand(FileUtil.java:1097)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.loadPermissionInfo(RawLocalFileSystem.java:659)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.getPermission(RawLocalFileSystem.java:634)\r\n\tat org.apache.hadoop.fs.LocatedFileStatus.<init>(LocatedFileStatus.java:49)\r\n\tat org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1733)\r\n\tat org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1713)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:270)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\r\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\r\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.loadPermissionInfo(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.getPermission(RawLocalFileSystem.java:634)\r\n\tat org.apache.hadoop.fs.LocatedFileStatus.<init>(LocatedFileStatus.java:49)\r\n\tat org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1733)\r\n\tat org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1713)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:270)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\r\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\r\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-df0d18886de6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrawblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \"\"\"\n\u001b[1;32m-> 1393\u001b[1;33m         \u001b[0mrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   1343\u001b[0m         \"\"\"\n\u001b[0;32m   1344\u001b[0m         \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1345\u001b[1;33m         \u001b[0mtotalParts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1346\u001b[0m         \u001b[0mpartsScanned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36mgetNumPartitions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \"\"\"\n\u001b[1;32m--> 409\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o29.partitions.\n: java.lang.RuntimeException: Error while running command to get file permissions : java.io.IOException: (null) entry in command string: null ls -F C:\\linkage_csv\\block_1.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:770)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:866)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:849)\r\n\tat org.apache.hadoop.fs.FileUtil.execCommand(FileUtil.java:1097)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.loadPermissionInfo(RawLocalFileSystem.java:659)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.getPermission(RawLocalFileSystem.java:634)\r\n\tat org.apache.hadoop.fs.LocatedFileStatus.<init>(LocatedFileStatus.java:49)\r\n\tat org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1733)\r\n\tat org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1713)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:270)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\r\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\r\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.loadPermissionInfo(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.getPermission(RawLocalFileSystem.java:634)\r\n\tat org.apache.hadoop.fs.LocatedFileStatus.<init>(LocatedFileStatus.java:49)\r\n\tat org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1733)\r\n\tat org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1713)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:270)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\r\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\r\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
     ]
    }
   ],
   "source": [
    "rawblocks.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"',\n",
      " '37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE',\n",
      " '39086,47614,1,?,1,?,1,1,1,1,1,TRUE',\n",
      " '70031,70237,1,?,1,?,1,1,1,1,1,TRUE',\n",
      " '84795,97439,1,?,1,?,1,1,1,1,1,TRUE',\n",
      " '36950,42116,1,?,1,1,1,1,1,1,1,TRUE',\n",
      " '42413,48491,1,?,1,?,1,1,1,1,1,TRUE',\n",
      " '25965,64753,1,?,1,?,1,1,1,1,1,TRUE',\n",
      " '49451,90407,1,?,1,?,1,1,1,1,0,TRUE',\n",
      " '39932,40902,1,?,1,?,1,1,1,1,1,TRUE']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "head = rawblocks.take(10) # returnm list type not RDD\n",
    "pprint(head)\n",
    "pprint(len(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"',\n",
       " '37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE',\n",
       " '39086,47614,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '70031,70237,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '84795,97439,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '36950,42116,1,?,1,1,1,1,1,1,1,TRUE',\n",
       " '42413,48491,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '25965,64753,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '49451,90407,1,?,1,?,1,1,1,1,0,TRUE',\n",
       " '39932,40902,1,?,1,?,1,1,1,1,1,TRUE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = sc.parallelize(head) # convert python list to RDD\n",
    "head.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isHeader(line):\n",
    "    if line.find(\"id_1\") == -1:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.filter(isHeader).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE',\n",
       " '39086,47614,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '70031,70237,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '84795,97439,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '36950,42116,1,?,1,1,1,1,1,1,1,TRUE',\n",
       " '42413,48491,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '25965,64753,1,?,1,?,1,1,1,1,1,TRUE',\n",
       " '49451,90407,1,?,1,?,1,1,1,1,0,TRUE',\n",
       " '39932,40902,1,?,1,?,1,1,1,1,1,TRUE']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head.filterNot(isHeader).length # AttributeError: 'RDD' object has no attribute 'filterNot'\n",
    "head.filter(lambda x: not isHeader(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.filter(lambda x: not isHeader(x)).count()\n",
    "# pyapark RDD has no length property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipping Code from the Client to the Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noheader = rawblocks.filter(lambda x: not isHeader(x))\n",
    "noheader.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From RDDs to Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = spark.read.option(\"header\", \"true\") \\\n",
    "                    .option(\"nullValue\", \"?\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .csv('linkage_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_fname_c2: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c2: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Data with the DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749132"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id_1: int, id_2: int, cmp_fname_c1: double, cmp_fname_c2: double, cmp_lname_c1: double, cmp_lname_c2: double, cmp_sex: int, cmp_bd: int, cmp_bm: int, cmp_by: int, cmp_plz: int, is_match: boolean]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {True: 20931, False: 5728201})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.rdd.map(lambda x: x.is_match).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|is_match|  count|\n",
      "+--------+-------+\n",
      "|   false|5728201|\n",
      "|    true|  20931|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.groupBy(\"is_match\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|    stddev(cmp_sex)|\n",
      "+-------------------+\n",
      "|0.20730111116897781|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+-------------------+\n",
      "|    stddev(cmp_sex)|        avg(cmp_bd)|\n",
      "+-------------------+-------------------+\n",
      "|0.20730111116897781|0.22446526708507172|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.agg({\"cmp_sex\": \"avg\", \"cmp_sex\":\"stddev\"}).show() # 같은컬럼 쓰면 하나밖에 안나옴\n",
    "parsed.agg({\"cmp_bd\": \"avg\", \"cmp_sex\":\"stddev\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|is_match|    cnt|\n",
      "+--------+-------+\n",
      "|   false|5728201|\n",
      "|    true|  20931|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.createOrReplaceTempView(\"linkage\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT is_match, COUNT(*) cnt\n",
    "    FROM linkage\n",
    "    GROUP BY is_match\n",
    "    ORDER BY cnt DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Summary Statistics for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+\n",
      "|summary|              id_1|              id_2|       cmp_fname_c1|      cmp_fname_c2|      cmp_lname_c1|       cmp_lname_c2|            cmp_sex|             cmp_bd|             cmp_bm|            cmp_by|            cmp_plz|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+\n",
      "|  count|           5749132|           5749132|            5748125|            103698|           5749132|               2464|            5749132|            5748337|            5748337|           5748337|            5736289|\n",
      "|   mean| 33324.48559643438| 66587.43558331935| 0.7129024704437266|0.9000176718903189|0.3156278193080383| 0.3184128315317443|  0.955001381078048|0.22446526708507172|0.48885529849763504|0.2227485966810923|0.00552866147434343|\n",
      "| stddev|23659.859374488064|23620.487613269695|0.38875835961628014|0.2713176105782334|0.3342336339615828|0.36856706620066537|0.20730111116897781|0.41722972238462636| 0.4998758236779031|0.4160909629831756|0.07414914925420046|\n",
      "|    min|                 1|                 6|                0.0|               0.0|               0.0|                0.0|                  0|                  0|                  0|                 0|                  0|\n",
      "|    max|             99980|            100000|                1.0|               1.0|               1.0|                1.0|                  1|                  1|                  1|                 1|                  1|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = parsed.describe()\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|summary|       cmp_fname_c1|      cmp_fname_c2|\n",
      "+-------+-------------------+------------------+\n",
      "|  count|            5748125|            103698|\n",
      "|   mean| 0.7129024704437266|0.9000176718903189|\n",
      "| stddev|0.38875835961628014|0.2713176105782334|\n",
      "|    min|                0.0|               0.0|\n",
      "|    max|                1.0|               1.0|\n",
      "+-------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = parsed.where(\"is_match = true\")\n",
    "matchSummary =  matches.describe()\n",
    "\n",
    "misses = parsed.filter(parsed.is_match == False) # $\"is_match\" --> parsed.is_match\n",
    "missSummary = misses.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|summary|             id_1|             id_2|       cmp_fname_c1|       cmp_fname_c2|        cmp_lname_c1|       cmp_lname_c2|            cmp_sex|             cmp_bd|              cmp_bm|             cmp_by|            cmp_plz|\n",
      "+-------+-----------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|  count|            20931|            20931|              20922|               1333|               20931|                475|              20931|              20925|               20925|              20925|              20902|\n",
      "|   mean|34575.72117911232|51259.95939037791| 0.9973163859635038| 0.9898900320318176|  0.9970152595958817|  0.969370167843852|  0.987291577086618| 0.9970848267622461|  0.9979450418160095| 0.9961290322580645| 0.9584250310975027|\n",
      "| stddev|21950.31285196913|24345.73345377519|0.03650667584833679|0.08251973727615237|0.043118807533945126|0.15345280740388917|0.11201570591216435|0.05391487659807981|0.045286127452170664|0.06209804856731055|0.19962063345931919|\n",
      "|    min|                5|                6|                0.0|                0.0|                 0.0|                0.0|                  0|                  0|                   0|                  0|                  0|\n",
      "|    max|            99946|            99996|                1.0|                1.0|                 1.0|                1.0|                  1|                  1|                   1|                  1|                  1|\n",
      "+-------+-----------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matchSummary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|summary|             id_1|             id_2|       cmp_fname_c1|       cmp_fname_c2|        cmp_lname_c1|       cmp_lname_c2|            cmp_sex|             cmp_bd|              cmp_bm|             cmp_by|            cmp_plz|\n",
      "+-------+-----------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|  count|            20931|            20931|              20922|               1333|               20931|                475|              20931|              20925|               20925|              20925|              20902|\n",
      "|   mean|34575.72117911232|51259.95939037791| 0.9973163859635038| 0.9898900320318176|  0.9970152595958817|  0.969370167843852|  0.987291577086618| 0.9970848267622461|  0.9979450418160095| 0.9961290322580645| 0.9584250310975027|\n",
      "| stddev|21950.31285196913|24345.73345377519|0.03650667584833679|0.08251973727615237|0.043118807533945126|0.15345280740388917|0.11201570591216435|0.05391487659807981|0.045286127452170664|0.06209804856731055|0.19962063345931919|\n",
      "|    min|                5|                6|                0.0|                0.0|                 0.0|                0.0|                  0|                  0|                   0|                  0|                  0|\n",
      "|    max|            99946|            99996|                1.0|                1.0|                 1.0|                1.0|                  1|                  1|                   1|                  1|                  1|\n",
      "+-------+-----------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matchSummary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting and Reshaping DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- id_1: string (nullable = true)\n",
      " |-- id_2: string (nullable = true)\n",
      " |-- cmp_fname_c1: string (nullable = true)\n",
      " |-- cmp_fname_c2: string (nullable = true)\n",
      " |-- cmp_lname_c1: string (nullable = true)\n",
      " |-- cmp_lname_c2: string (nullable = true)\n",
      " |-- cmp_sex: string (nullable = true)\n",
      " |-- cmp_bd: string (nullable = true)\n",
      " |-- cmp_bm: string (nullable = true)\n",
      " |-- cmp_by: string (nullable = true)\n",
      " |-- cmp_plz: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(summary)\n",
    "# pyspark.sql.dataframe.DataFrame \n",
    "# do not have flatmap method, use DataFrame.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('count', 'id_1', 5749132.0),\n",
       " ('count', 'id_2', 5749132.0),\n",
       " ('count', 'cmp_fname_c1', 5748125.0),\n",
       " ('count', 'cmp_fname_c2', 103698.0),\n",
       " ('count', 'cmp_lname_c1', 5749132.0),\n",
       " ('count', 'cmp_lname_c2', 2464.0),\n",
       " ('count', 'cmp_sex', 5749132.0),\n",
       " ('count', 'cmp_bd', 5748337.0),\n",
       " ('count', 'cmp_bm', 5748337.0),\n",
       " ('count', 'cmp_by', 5748337.0),\n",
       " ('count', 'cmp_plz', 5736289.0),\n",
       " ('mean', 'id_1', 33324.48559643438),\n",
       " ('mean', 'id_2', 66587.43558331935),\n",
       " ('mean', 'cmp_fname_c1', 0.7129024704437266),\n",
       " ('mean', 'cmp_fname_c2', 0.9000176718903189),\n",
       " ('mean', 'cmp_lname_c1', 0.3156278193080383),\n",
       " ('mean', 'cmp_lname_c2', 0.3184128315317443),\n",
       " ('mean', 'cmp_sex', 0.955001381078048),\n",
       " ('mean', 'cmp_bd', 0.22446526708507172),\n",
       " ('mean', 'cmp_bm', 0.48885529849763504),\n",
       " ('mean', 'cmp_by', 0.2227485966810923),\n",
       " ('mean', 'cmp_plz', 0.00552866147434343),\n",
       " ('stddev', 'id_1', 23659.859374488064),\n",
       " ('stddev', 'id_2', 23620.487613269695),\n",
       " ('stddev', 'cmp_fname_c1', 0.38875835961628014),\n",
       " ('stddev', 'cmp_fname_c2', 0.2713176105782334),\n",
       " ('stddev', 'cmp_lname_c1', 0.3342336339615828),\n",
       " ('stddev', 'cmp_lname_c2', 0.36856706620066537),\n",
       " ('stddev', 'cmp_sex', 0.20730111116897781),\n",
       " ('stddev', 'cmp_bd', 0.41722972238462636),\n",
       " ('stddev', 'cmp_bm', 0.4998758236779031),\n",
       " ('stddev', 'cmp_by', 0.4160909629831756),\n",
       " ('stddev', 'cmp_plz', 0.07414914925420046),\n",
       " ('min', 'id_1', 1.0),\n",
       " ('min', 'id_2', 6.0),\n",
       " ('min', 'cmp_fname_c1', 0.0),\n",
       " ('min', 'cmp_fname_c2', 0.0),\n",
       " ('min', 'cmp_lname_c1', 0.0),\n",
       " ('min', 'cmp_lname_c2', 0.0),\n",
       " ('min', 'cmp_sex', 0.0),\n",
       " ('min', 'cmp_bd', 0.0),\n",
       " ('min', 'cmp_bm', 0.0),\n",
       " ('min', 'cmp_by', 0.0),\n",
       " ('min', 'cmp_plz', 0.0),\n",
       " ('max', 'id_1', 99980.0),\n",
       " ('max', 'id_2', 100000.0),\n",
       " ('max', 'cmp_fname_c1', 1.0),\n",
       " ('max', 'cmp_fname_c2', 1.0),\n",
       " ('max', 'cmp_lname_c1', 1.0),\n",
       " ('max', 'cmp_lname_c2', 1.0),\n",
       " ('max', 'cmp_sex', 1.0),\n",
       " ('max', 'cmp_bd', 1.0),\n",
       " ('max', 'cmp_bm', 1.0),\n",
       " ('max', 'cmp_by', 1.0),\n",
       " ('max', 'cmp_plz', 1.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = summary.schema\n",
    "# python has no type: double\n",
    "longForm = summary.rdd.flatMap(lambda row: [(row[0], schema[i].name, float(row[i])) for i in range(1,len(row))])\n",
    "\n",
    "longForm.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-------------------+\n",
      "|metric|       field|              value|\n",
      "+------+------------+-------------------+\n",
      "| count|        id_1|          5749132.0|\n",
      "| count|        id_2|          5749132.0|\n",
      "| count|cmp_fname_c1|          5748125.0|\n",
      "| count|cmp_fname_c2|           103698.0|\n",
      "| count|cmp_lname_c1|          5749132.0|\n",
      "| count|cmp_lname_c2|             2464.0|\n",
      "| count|     cmp_sex|          5749132.0|\n",
      "| count|      cmp_bd|          5748337.0|\n",
      "| count|      cmp_bm|          5748337.0|\n",
      "| count|      cmp_by|          5748337.0|\n",
      "| count|     cmp_plz|          5736289.0|\n",
      "|  mean|        id_1|  33324.48559643438|\n",
      "|  mean|        id_2|  66587.43558331935|\n",
      "|  mean|cmp_fname_c1| 0.7129024704437266|\n",
      "|  mean|cmp_fname_c2| 0.9000176718903189|\n",
      "|  mean|cmp_lname_c1| 0.3156278193080383|\n",
      "|  mean|cmp_lname_c2| 0.3184128315317443|\n",
      "|  mean|     cmp_sex|  0.955001381078048|\n",
      "|  mean|      cmp_bd|0.22446526708507172|\n",
      "|  mean|      cmp_bm|0.48885529849763504|\n",
      "+------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\"metric\", \"field\", \"value\"]\n",
    "longDF = longForm.toDF(cols) # 파라메터 인풋 바뀜 *cols넣으면 에러남 \n",
    "longDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------------------+\n",
      "|       field|    count|               mean|\n",
      "+------------+---------+-------------------+\n",
      "|        id_2|5749132.0|  66587.43558331935|\n",
      "|     cmp_plz|5736289.0|0.00552866147434343|\n",
      "|cmp_lname_c1|5749132.0| 0.3156278193080383|\n",
      "|cmp_lname_c2|   2464.0| 0.3184128315317443|\n",
      "|     cmp_sex|5749132.0|  0.955001381078048|\n",
      "|      cmp_bm|5748337.0|0.48885529849763504|\n",
      "|cmp_fname_c2| 103698.0| 0.9000176718903189|\n",
      "|cmp_fname_c1|5748125.0| 0.7129024704437266|\n",
      "|        id_1|5749132.0|  33324.48559643438|\n",
      "|      cmp_bd|5748337.0|0.22446526708507172|\n",
      "|      cmp_by|5748337.0| 0.2227485966810923|\n",
      "+------------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first\n",
    "\n",
    "wideDF = longDF.groupBy(\"field\") \\\n",
    "    .pivot(\"metric\", [\"count\", \"mean\", \"stddev\", \"min\", \"max\"]) \\\n",
    "    .agg(first(\"value\"))\n",
    "\n",
    "wideDF.select(\"field\", \"count\", \"mean\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivotSummary(desc): # desc: DataFrame\n",
    "    schema = desc.schema\n",
    "    lf = desc.rdd \\\n",
    "        .flatMap(lambda row: [(row[0], schema[i].name, float(row[i])) for i in range(1,len(row))]) \\\n",
    "        .toDF([\"metric\", \"field\", \"value\"])\n",
    "    \n",
    "    lf = lf.groupBy(\"field\") \\\n",
    "        .pivot(\"metric\", [\"count\", \"mean\", \"stddev\", \"min\", \"max\"]) \\\n",
    "        .agg(first(\"value\"))\n",
    "    \n",
    "    return lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+------------------+--------------------+---+-------+\n",
      "|       field|  count|              mean|              stddev|min|    max|\n",
      "+------------+-------+------------------+--------------------+---+-------+\n",
      "|        id_2|20931.0| 51259.95939037791|   24345.73345377519|6.0|99996.0|\n",
      "|     cmp_plz|20902.0|0.9584250310975027| 0.19962063345931919|0.0|    1.0|\n",
      "|cmp_lname_c1|20931.0|0.9970152595958817|0.043118807533945126|0.0|    1.0|\n",
      "|cmp_lname_c2|  475.0| 0.969370167843852| 0.15345280740388917|0.0|    1.0|\n",
      "|     cmp_sex|20931.0| 0.987291577086618| 0.11201570591216435|0.0|    1.0|\n",
      "|      cmp_bm|20925.0|0.9979450418160095|0.045286127452170664|0.0|    1.0|\n",
      "|cmp_fname_c2| 1333.0|0.9898900320318176| 0.08251973727615237|0.0|    1.0|\n",
      "|cmp_fname_c1|20922.0|0.9973163859635038| 0.03650667584833679|0.0|    1.0|\n",
      "|        id_1|20931.0| 34575.72117911232|   21950.31285196913|5.0|99946.0|\n",
      "|      cmp_bd|20925.0|0.9970848267622461| 0.05391487659807981|0.0|    1.0|\n",
      "|      cmp_by|20925.0|0.9961290322580645| 0.06209804856731055|0.0|    1.0|\n",
      "+------------+-------+------------------+--------------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matchSummaryT = pivotSummary(matchSummary)\n",
    "missSummaryT = pivotSummary(missSummary)\n",
    "\n",
    "matchSummaryT.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining DataFrames and Selecting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+--------------------+\n",
      "|       field|    total|               delta|\n",
      "+------------+---------+--------------------+\n",
      "|     cmp_plz|5736289.0|  0.9563812499852176|\n",
      "|cmp_lname_c2|   2464.0|  0.8064147192926266|\n",
      "|      cmp_by|5748337.0|  0.7762059675300512|\n",
      "|      cmp_bd|5748337.0|   0.775442311783404|\n",
      "|cmp_lname_c1|5749132.0|  0.6838772482594513|\n",
      "|      cmp_bm|5748337.0|  0.5109496938298685|\n",
      "|cmp_fname_c1|5748125.0|  0.2854529057459947|\n",
      "|cmp_fname_c2| 103698.0| 0.09104268062280174|\n",
      "|     cmp_sex|5749132.0|0.032408185250332844|\n",
      "+------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matchSummaryT.createOrReplaceTempView(\"match_desc\")\n",
    "missSummaryT.createOrReplaceTempView(\"miss_desc\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT a.field, a.count + b.count total, a.mean - b.mean delta\n",
    "FROM match_desc a INNER JOIN miss_desc b ON a.field = b.field\n",
    "WHERE a.field NOT IN (\"id_1\", \"id_2\")\n",
    "ORDER BY delta DESC, total DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Models for Production Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python do not need case class\n",
    "# matchData = parsed.as[MatchData]\n",
    "matchData = parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark에서 Option[T] 타입을 지원하지 않으므로 직접 구현\n",
    "def getOrElse(val, el):\n",
    "    try:\n",
    "        return float(val)\n",
    "    except:\n",
    "        return el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreMatchData(md): # md: MatchData\n",
    "    return  getOrElse(md.cmp_lname_c1, 0.0) + getOrElse(md.cmp_plz, 0.0) \\\n",
    "            + getOrElse(md.cmp_by, 0.0) + getOrElse(md.cmp_bd, 0.0) + getOrElse(md.cmp_bm, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = matchData.rdd.map(lambda md: (scoreMatchData(md), md.is_match)) \\\n",
    "                        .toDF([\"score\", \"is_match\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+\n",
      "|above| true|  false|\n",
      "+-----+-----+-------+\n",
      "| true|20871|    637|\n",
      "|false|   60|5727564|\n",
      "+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def crossTabs(scored, t): # scored: DataFrame, t: Double\n",
    "    return scored.selectExpr(\"score >= \"+str(t)+\" as above\", \"is_match\") \\\n",
    "                .groupBy(\"above\") \\\n",
    "                .pivot(\"is_match\", [\"true\", \"false\"]) \\\n",
    "                .count()\n",
    "\n",
    "crossTabs(scored, 4.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+\n",
      "|above| true|  false|\n",
      "+-----+-----+-------+\n",
      "| true|20931| 596414|\n",
      "|false| null|5131787|\n",
      "+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossTabs(scored, 2.0).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
