{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gutenburg Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
      "887071 192427 7752 [['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())\n",
    "\n",
    "a = len(gutenberg.raw('austen-emma.txt'))\n",
    "\n",
    "b = len(gutenberg.words('austen-emma.txt'))\n",
    "c = len(gutenberg.sents('austen-emma.txt'))\n",
    "\n",
    "macbeth = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "\n",
    "print(a ,b, c,macbeth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# brown sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "# print(brown.categories())\n",
    "a = brown.words(categories='news')\n",
    "b = brown.words(fileids=['cg22'])\n",
    "c = brown.sents(categories=['news' , 'editorial'])\n",
    "fdist = nltk.FreqDist([w.lower() for w in a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 6386, ',': 5188, '.': 4030, 'of': 2861, 'and': 2186, 'to': 2144, 'a': 2130, 'in': 2020, 'for': 969, 'that': 829, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist((genre , word)\n",
    "                               for genre in brown.categories()\n",
    "                               for word in brown.words(categories = genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('adventure', FreqDist({'.': 4057, ',': 3488, 'the': 3370, 'and': 1622, 'a': 1354, 'of': 1322, 'to': 1309, '``': 998, \"''\": 995, 'was': 914, ...})), ('belles_lettres', FreqDist({'the': 9726, ',': 9166, '.': 6397, 'of': 6289, 'and': 4282, 'to': 4084, 'a': 3308, 'in': 3089, 'that': 1896, 'is': 1799, ...})), ('editorial', FreqDist({'the': 3508, ',': 2766, '.': 2481, 'of': 1976, 'to': 1554, 'and': 1302, 'a': 1095, 'in': 1001, 'is': 744, 'that': 578, ...})), ('fiction', FreqDist({',': 3654, '.': 3639, 'the': 3423, 'and': 1696, 'to': 1489, 'of': 1419, 'a': 1281, 'was': 1082, 'in': 916, 'he': 813, ...})), ('government', FreqDist({'the': 4143, ',': 3405, 'of': 3031, '.': 2493, 'and': 1923, 'to': 1829, 'in': 1319, 'a': 867, 'for': 806, 'is': 649, ...})), ('hobbies', FreqDist({'the': 4300, ',': 3849, '.': 3453, 'of': 2390, 'and': 2144, 'to': 1797, 'a': 1737, 'in': 1427, 'is': 959, 'for': 776, ...})), ('humor', FreqDist({',': 1331, 'the': 930, '.': 877, 'of': 515, 'and': 512, 'a': 505, 'to': 463, '``': 343, \"''\": 340, 'in': 334, ...})), ('learned', FreqDist({'the': 11079, ',': 8242, 'of': 7418, '.': 6773, 'and': 4237, 'to': 3882, 'in': 3644, 'a': 3215, 'is': 2403, 'that': 1695, ...})), ('lore', FreqDist({'the': 6328, ',': 5519, '.': 4367, 'of': 3668, 'and': 2758, 'to': 2530, 'a': 2304, 'in': 2001, 'is': 1007, 'that': 984, ...})), ('mystery', FreqDist({'.': 3326, ',': 2805, 'the': 2573, 'to': 1284, 'and': 1215, 'a': 1136, 'of': 903, 'was': 820, '``': 740, \"''\": 738, ...})), ('news', FreqDist({'the': 5580, ',': 5188, '.': 4030, 'of': 2849, 'and': 2146, 'to': 2116, 'a': 1993, 'in': 1893, 'for': 943, 'The': 806, ...})), ('religion', FreqDist({'the': 2295, ',': 1913, 'of': 1494, '.': 1382, 'and': 921, 'to': 882, 'in': 724, 'a': 655, 'is': 533, 'that': 475, ...})), ('reviews', FreqDist({',': 2318, 'the': 2048, '.': 1549, 'of': 1299, 'and': 1103, 'a': 874, 'to': 706, 'in': 656, 'is': 513, '``': 390, ...})), ('romance', FreqDist({',': 3899, '.': 3736, 'the': 2758, 'and': 1776, 'to': 1502, 'a': 1335, 'of': 1186, '``': 1045, \"''\": 1044, 'was': 993, ...})), ('science_fiction', FreqDist({',': 791, '.': 786, 'the': 652, 'of': 321, 'to': 305, 'and': 278, '``': 235, \"''\": 235, 'a': 222, 'was': 198, ...}))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n"
     ]
    }
   ],
   "source": [
    "genres = ['news' , 'religion' , 'hobbies' , 'science_fiction' , 'romance']\n",
    "modals = ['can' ,'could' , 'may' , 'might' , 'must' , 'will']\n",
    "cfd.tabulate(conditions = genres , samples = modals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus 내가 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README',\n",
       " 'english-kjv.txt',\n",
       " 'english-web.txt',\n",
       " 'finnish.txt',\n",
       " 'french.txt',\n",
       " 'german.txt',\n",
       " 'lolcat.txt',\n",
       " 'portuguese.txt',\n",
       " 'swedish.txt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycor = 'C:\\world_news'\n",
    "files = PlaintextCorpusReader(mycor , '.*')\n",
    "files.fileids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In', 'the', 'beginning', 'God', 'created', 'the', ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.words('english-kjv.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop word sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    " \n",
    "stop_words = set(stopwords.words('english'))\n",
    " \n",
    "word_tokens = word_tokenize(example_sent)\n",
    " \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    " \n",
    "filtered_sentence = []\n",
    " \n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    " \n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
